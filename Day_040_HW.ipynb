{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "使用 Sklearn 中的 Lasso, Ridge 模型，來訓練各種資料集，務必了解送進去模型訓練的**資料型態**為何，也請了解模型中各項參數的意義。\n",
    "\n",
    "機器學習的模型非常多種，但要訓練的資料多半有固定的格式，確保你了解訓練資料的格式為何，這樣在應用新模型時，就能夠最快的上手開始訓練！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習時間\n",
    "試著使用 sklearn datasets 的其他資料集 (boston, ...)，來訓練自己的線性迴歸模型，並加上適當的正則化來觀察訓練情形。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn import datasets , linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Step1] Data loading, preprocessing, and exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 載入酒類資料集, 並觀察原始資料\n",
    "boston = datasets.load_boston()\n",
    "boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "0       15.3  396.90   4.98    24.0  \n",
       "1       17.8  396.90   9.14    21.6  \n",
       "2       17.8  392.83   4.03    34.7  \n",
       "3       18.7  394.63   2.94    33.4  \n",
       "4       18.7  396.90   5.33    36.2  \n",
       "..       ...     ...    ...     ...  \n",
       "501     21.0  391.99   9.67    22.4  \n",
       "502     21.0  396.90   9.08    20.6  \n",
       "503     21.0  396.90   5.64    23.9  \n",
       "504     21.0  393.45   6.48    22.0  \n",
       "505     21.0  396.90   7.88    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 整理原始資料, 並進行EDA\n",
    "df_boston = pd.DataFrame(boston['data'], columns=boston['feature_names'])\n",
    "df_target = pd.DataFrame(boston['target'], columns=['target'])\n",
    "df = pd.concat([df_boston, df_target], axis=1)\n",
    "df  # 全為數值型資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston.isnull().sum()  #沒有缺值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_boston.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Step2] Least Square Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此資料集為回歸問題, 故使用LinearRegression\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_boston, df_target, test_size=0.1, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeficient :\n",
      "CRIM: -0.12585665878406954\n",
      "ZN: 0.0484257396100201\n",
      "INDUS: 0.01840852809252633\n",
      "CHAS: 3.085095691516899\n",
      "NOX: -17.327701820564606\n",
      "RM: 3.6167471330861467\n",
      "AGE: 0.0021918185271774765\n",
      "DIS: -1.4936113225001264\n",
      "RAD: 0.3199792000272681\n",
      "TAX: -0.01272946486141267\n",
      "PTRATIO: -0.927469085924641\n",
      "B: 0.009509124683760478\n",
      "LSTAT: -0.5335924706228666\n",
      "\n",
      "Mean squared error: 17.039\n"
     ]
    }
   ],
   "source": [
    "#各特徵係數\n",
    "print('coeficient :')\n",
    "\n",
    "for i, j in zip(df_boston.columns, reg.coef_[0]):\n",
    "    print(f'{i}: {j}')\n",
    "print()    \n",
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(f\"Mean squared error: {round(mean_squared_error(y_test, y_pred), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Step3] Lasso Regression (L1 norm.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_boston, df_target, test_size=0.1, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "Lasso = linear_model.Lasso(alpha=2)\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "Lasso.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = Lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeficient :\n",
      "\n",
      "CRIM: -0.02373776827126448\n",
      "ZN: 0.03337257117417263\n",
      "INDUS: -0.0\n",
      "CHAS: 0.0\n",
      "NOX: -0.0\n",
      "RM: 0.0\n",
      "AGE: 0.04645090268516165\n",
      "DIS: -0.05385332233022369\n",
      "RAD: 0.17209628733167168\n",
      "TAX: -0.011660716114175698\n",
      "PTRATIO: -0.5564866826886662\n",
      "B: 0.007101118645512347\n",
      "LSTAT: -0.8213388039730934\n",
      "\n",
      "Feature deletion candidates: \n",
      " (features listed below are considered to be removed from the training data for better fitting of the model) \n",
      " ['INDUS', 'CHAS', 'NOX', 'RM']\n",
      "\n",
      "Mean squared error: 28.509\n"
     ]
    }
   ],
   "source": [
    "#各特徵係數\n",
    "print('coeficient :', end='\\n\\n')\n",
    "delete_list = []\n",
    "for i, j in zip(df_boston.columns, Lasso.coef_):\n",
    "    if j ==0:\n",
    "        delete_list.append(i)\n",
    "    print(f'{i}: {j}')\n",
    "print()\n",
    "print(f'Feature deletion candidates: \\n (features listed below are considered to be removed from the training data for better fitting of the model) \\n {delete_list}')\n",
    "print()\n",
    "\n",
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(f\"Mean squared error: {round(mean_squared_error(y_test, y_pred), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeficient :\n",
      "CRIM: -0.12056812160932537\n",
      "ZN: 0.07515226973959761\n",
      "AGE: 0.009812921056037264\n",
      "DIS: -1.3646340545387323\n",
      "RAD: 0.4047200581175486\n",
      "TAX: -0.020795341815980296\n",
      "PTRATIO: -0.9465659138822131\n",
      "B: 0.008470094887250857\n",
      "LSTAT: -0.8324425584628288\n",
      "\n",
      "Mean squared error: 24.455\n"
     ]
    }
   ],
   "source": [
    "# 驗證 L1 的 feature selection\n",
    "df_temp = df_boston.drop(['INDUS', 'CHAS', 'NOX', 'RM'], axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_temp, df_target, test_size=0.1, random_state=4)\n",
    "reg2 = linear_model.LinearRegression()\n",
    "reg2.fit(x_train, y_train)\n",
    "y_pred = reg2.predict(x_test)\n",
    "\n",
    "#各特徵係數\n",
    "print('coeficient :')\n",
    "\n",
    "for i, j in zip(df_temp.columns, reg2.coef_[0]):\n",
    "    print(f'{i}: {j}')\n",
    "print()\n",
    "print(f\"Mean squared error: {round(mean_squared_error(y_test, y_pred), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Step4] Ridge Regression (L2 norm.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_boston, df_target, test_size=0.1, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "Rid = linear_model.Ridge(alpha=1)\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "Rid.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = Rid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeficient :\n",
      "\n",
      "CRIM: -0.12248803669322372\n",
      "ZN: 0.04954830487400808\n",
      "INDUS: -0.011583983289705637\n",
      "CHAS: 2.8907182033260583\n",
      "NOX: -10.040289498860082\n",
      "RM: 3.6667430619934596\n",
      "AGE: -0.00443653914589698\n",
      "DIS: -1.389908621735465\n",
      "RAD: 0.30228629158784265\n",
      "TAX: -0.013225979812376196\n",
      "PTRATIO: -0.8521417939742221\n",
      "B: 0.009867083531947405\n",
      "LSTAT: -0.5436811301680253\n",
      "\n",
      "Mean squared error: 17.352\n"
     ]
    }
   ],
   "source": [
    "#各特徵係數\n",
    "print('coeficient :' ,end='\\n\\n')\n",
    "\n",
    "for i, j in zip(df_boston.columns, Rid.coef_[0]):\n",
    "    print(f'{i}: {j}')\n",
    "\n",
    "print()\n",
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(f\"Mean squared error: {round(mean_squared_error(y_test, y_pred), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
