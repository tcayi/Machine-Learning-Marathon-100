{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [作業目標]\n",
    "\n",
    "持續接觸有關機器學習的相關專案與最新技術，透過觀察頂尖公司的機器學習文章，來了解各公司是怎麼應用機器學習在實際的專案上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今天的作業希望大家能夠看看全球機器學習巨頭們在做的機器學習專案。以 google 為例，下圖是 Google 內部專案使用機器學習的數量，隨著時間進展，現在早已超過 2000 個專案在使用機器學習。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cdn-images-1.medium.com/max/800/1*U_L8qI8RmYS-MOBrYvXhSA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "底下幫同學整理幾間知名企業的 blog 或機器學習網站 (自行搜尋也可)，這些網站都會整理最新的機器學習專案或者是技術文章，請挑選一篇文章閱讀並試著回答\n",
    "1. 專案的目標？ (要解決什麼問題）\n",
    "2. 使用的技術是？ (只需知道名稱即可，例如：使用 CNN 卷積神經網路做影像分類)\n",
    "3. 資料來源？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Google AI blog](https://ai.googleblog.com/)\n",
    "- [Facebook Research blog](https://research.fb.com/blog/)\n",
    "- [Apple machine learning journal](https://machinelearning.apple.com/)\n",
    "- [機器之心](https://www.jiqizhixin.com/)\n",
    "- [雷鋒網](http://www.leiphone.com/category/ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Article used: Google AI Blog - LEAF: A Learnable Frontend for Audio Classification\n",
    "    \n",
    "Developing Machine Learning Models has seen massive improvements over the past several years, this projects aim is to use deep neural classifiers to recognize speech, understand music, or classify animal vocalizations such as bird calls, and in the future, aim to improve sound recognisation models for new audio-related tasks.\n",
    "\n",
    "The technique that is used is LEAF - LEarnable Audio Frontend. It is a neural network that can be initialized to approximate mel filter banks, and then be trained jointly with any audio classifier to adapt to the task at hand, while only adding a handful of parameters to the full model. The aim of using mel filter banks is to mimic non-linear human ear perception of sound, as human ears are more discriminative at lower frequencies and less discriminative at higher frequencies.\n",
    "\n",
    "In order to create a mel filterbank, one captures the sound’s time-variability by dividing the sound data into segments. Then, one performs filtering, by passing the windowed segments through a set of fixed frequency filters, that replicate the human logarithmic sensitivity to pitch. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
